Diplodatos
02 Análisis Exploratorio y curación de datos

Práctico 05 - Breast Cancer 

Dataset: Breast Cancer Wisconsin Diagnostic - UCI ML Repository

Aplicar KNN para predecir a qué categoría pertenece cada registro de paciente: Benigno o Maligno.
Utilizar dos métodos de normalización, y ensayar diferentes valores para el parámetro k.


## Importación de datos
```{r}
data <- read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data",header=FALSE)
data <- data[-1]
str(data)
```
La primera variable se descarga pues corresponde a un ID.
La segunda, a diagnóstico Benigno y Maligno
```{r}
table(data$V2)
```
Se examina la información general, de cada variable.
```{r}
summary(data)
```
## Normalización
Bien. Se crea una función para normalizar los datos (minmax)

```{r}
normalize<-function(x) {
  return ((x-min(x))/(max(x)-min(x)))
}
```

Se aplica a los datos y se observan dos features testigo.

```{r}
data_n <- as.data.frame(lapply(data[2:31], normalize))
summary(data_n$V3)
summary(data_n$V14)
```
## Train-test split
Para simular una aplicación, se separan los datos en muestras de entrenamiento y validación para medir la precisión predictiva del modelo.

```{r}
data_train <- data_n[1:469, ]
data_test <- data_n[470:569, ]
data_train_labels <- data[1:469, 1]
data_test_labels <- data[470:569, 1]
```

## KNN para estandarización minmax
Se aplica un algoritmo de KNN. En este caso, el set de entrenamiento no es exactamente para entrenar un modelo, sino que se utiliza como vecindario para estudiar los vecinos que corresponden a cada elemento del set test.

```{r}
library(class)
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=1)
```
¿Qué tan precisas resultaron las predicciones de clases?
```{r}
library(gmodels)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq = FALSE )
```


Se comparan los resultados con los de una normalización Z para los datos.
Se prueban a su vez valores alternativos de k

## KNN para normalización Z
```{r}
znormalize <- function(x) {
  return ((x-mean(x))/sd(x))
}
```

```{r}
data_zn <- as.data.frame(lapply(data[2:31], znormalize))
summary(data_zn$V3)
summary(data_zn$V14)
```

En este caso, la media es cero.

```{r}
zdata_train <- data_zn[1:469, ]
zdata_test <- data_zn[470:569, ]
```

```{r}
zdata_test_pred <- knn(train=zdata_train, test=zdata_test, cl=data_train_labels, k=1)
CrossTable(x=data_test_labels, y=zdata_test_pred, prop.chisq = FALSE)
```

La predicción mejora muy levemente, sumando un acierto en la predicción de valores benignos.

## Ensayo de diferentes valores para k
### Para k = 5
```{r}
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=5)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq = FALSE )
```

### Para k = 10
```{r}
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=10)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq = FALSE )
```

### Para k = 25
```{r}
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=25)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq = FALSE )
```

### Resultados
En todos los casos, las predicciones mejoran con más vecinos (al menos hasta el límite ensayado)
Con 25 vecinos, se alcanzó un 98% de aciertos.

## Fin de la notebook







